####题目一：
思路：两表join，结果按照字段进行统计，见XIAODAKA.sql
####题目二：
思路：定义结构体描述version然后定义大小比较关系。
1.输出最大的version，通过一次遍历完成：interview.xioadaka.Version.findLargestVersion
2.多个version的排序号码，先排序然后一次遍历输出序号：interview.xioadaka.Version.getAllVersionSeq
3.思路：多次读入小文件，按照小块内进行排序，然后对于多个排序完的小文件进行归并排序
#### 题目三：
思路：关于多日的用户流存，我以前做的是用spark写的，这个写HQl的话，我就大致说说思路了。
具体没落在HQl上，如果是算某一天之后的七日内的留存，还是通过当天的新增用户left join 之后每天的数据（每天的数据可以打上当日数据这个字段），按照当日新增用户的id进行left join，
得到类似（当日新增用户id，之后某一天活跃日期），然后基于按照key进行聚合汇总。
#### 题目四：
1.遇到过的问题：
    在集群上跑日常的指标的时候出现同一个任务和几乎不变的数据量级，但是存在job完成时间差异很大的情况，比如同样是1000core-6G有些时候1个小时，有些时候5个小时，这种情况，导致当天出指标的时间明显后移。
    这种一般从集群装态还有日常的数据量上看，我一般是从新跑一下这个job，看看是不是当时集群资源不足或者数据中有潜在的倾斜的情况。

2.平时一些学习方法：
多数时候是自己看视频，记笔记，大数据一般需要集群，自己通过虚拟机搭建一下环境，虽然配置不高，但是基本的框架的用法可以练习一下。定时复习，自己有专门的总结和复习策略，但是还是毕竟实际开发中用到的部分很少得到实践，有时候会很爱忘。

3.对于大数据的一些看法和自身的规划：
我始终认为数据可以解释规律，结合最近火热起来的AI，数据+模型我觉得是以后的主要方向，但是我自身来看，很少有能有机会进入到实际生产中的AI落地应用上，进入大数据也是进入到现在公司的人员安排，不过挺幸运，这个领域很广很深，即使现在我看到的也足够我一直学习和实际下去。
我现在工作经验和实践经验很少，但是我希望我能一直保持一个学习的态度，目前我觉得我靠近一点的是数仓方向，自己也在不断的补全数据仓库的知识。